{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c78917",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sequence modeling of time series\n",
    "* Recurrent neural nets are popular when the data has a temporal component\n",
    "* A popular sequence model is known as the \"Long Short Term Memory\" (LSTM) network\n",
    "    * LSTM models are able to retain information across long time scales in the input sequence\n",
    "* Here we will apply the LSTM to our EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86705a93",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load the data\n",
    "* The second and third dimensions are swapped to accommodate the upcoming model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af5d6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/P300.mat' # the data file\n",
    "import scipy.io as sio # the library that we use to load Matlab data into Python\n",
    "data = sio.loadmat(filename)\n",
    "x_train = np.swapaxes(data['X_train'],1,2)\n",
    "x_test = np.swapaxes(data['X_test'],1,2)\n",
    "y_train = data['Y_train']\n",
    "y_test = data['Y_test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1dd004",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating the model\n",
    "* We will work with the Keras LSTM class \n",
    "* A key parameter is the number of hidden units in our LSTM layer - here we start with 100 units\n",
    "* We add a \"dropout\" parameter to try to mitigate overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc0da09b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 20)                6800      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,842\n",
      "Trainable params: 6,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "input_shape=(128,64) # this tells Keras the shape of the data that will be passed to it for training/testing\n",
    "n_classes=2\n",
    "n_lstm_units=20\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.LSTM(n_lstm_units,dropout=0.2),\n",
    "        keras.layers.Dense(n_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374f0195",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compile the model to prepare for training\n",
    "* We will use the same training parameters as previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "839b6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128  # how many training examples in each \"batch\" used to compute gradient of loss function\n",
    "epochs = 30 # how many passes through the data we want the fitting to take\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceec1de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fitting the model\n",
    "* Note that the LSTM is a complex architecture and is thus heavily parameterized\n",
    "* We will pay close attention to possible overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9c81041",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "9/9 [==============================] - 2s 33ms/step - loss: 0.6728 - accuracy: 0.6087 - auc_5: 0.6467\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5281 - accuracy: 0.7873 - auc_5: 0.8168\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4830 - accuracy: 0.8204 - auc_5: 0.8412\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4612 - accuracy: 0.8299 - auc_5: 0.8523\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4651 - accuracy: 0.8355 - auc_5: 0.8460\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4467 - accuracy: 0.8365 - auc_5: 0.8595\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4502 - accuracy: 0.8384 - auc_5: 0.8612\n",
      "Epoch 8/30\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4304 - accuracy: 0.8403 - auc_5: 0.8715\n",
      "Epoch 9/30\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.4320 - accuracy: 0.8374 - auc_5: 0.8712\n",
      "Epoch 10/30\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4247 - accuracy: 0.8374 - auc_5: 0.8775\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4201 - accuracy: 0.8412 - auc_5: 0.8791\n",
      "Epoch 12/30\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.4144 - accuracy: 0.8412 - auc_5: 0.8882\n",
      "Epoch 13/30\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4128 - accuracy: 0.8431 - auc_5: 0.8850\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4098 - accuracy: 0.8431 - auc_5: 0.8877\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4036 - accuracy: 0.8450 - auc_5: 0.8908\n",
      "Epoch 16/30\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4077 - accuracy: 0.8431 - auc_5: 0.8879\n",
      "Epoch 17/30\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4063 - accuracy: 0.8469 - auc_5: 0.8923\n",
      "Epoch 18/30\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3939 - accuracy: 0.8450 - auc_5: 0.8990\n",
      "Epoch 19/30\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3898 - accuracy: 0.8478 - auc_5: 0.9013\n",
      "Epoch 20/30\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3843 - accuracy: 0.8535 - auc_5: 0.9046\n",
      "Epoch 21/30\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3955 - accuracy: 0.8497 - auc_5: 0.8977\n",
      "Epoch 22/30\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3867 - accuracy: 0.8459 - auc_5: 0.9041\n",
      "Epoch 23/30\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3837 - accuracy: 0.8450 - auc_5: 0.9058\n",
      "Epoch 24/30\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3807 - accuracy: 0.8497 - auc_5: 0.9058\n",
      "Epoch 25/30\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3806 - accuracy: 0.8497 - auc_5: 0.9082\n",
      "Epoch 26/30\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3780 - accuracy: 0.8526 - auc_5: 0.9074\n",
      "Epoch 27/30\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3722 - accuracy: 0.8535 - auc_5: 0.9114\n",
      "Epoch 28/30\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3735 - accuracy: 0.8554 - auc_5: 0.9112\n",
      "Epoch 29/30\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3680 - accuracy: 0.8554 - auc_5: 0.9141\n",
      "Epoch 30/30\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3745 - accuracy: 0.8488 - auc_5: 0.9101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd79b244610>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc7da28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluating the sequence model\n",
    "* The training performance was quite high, but as always, we need to test on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb99691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 6ms/step - loss: 0.4271 - accuracy: 0.8396 - auc_5: 0.8809\n",
      "Model accuracy = 0.8396226167678833\n",
      "Model AUROC = 0.8808525800704956\n"
     ]
    }
   ],
   "source": [
    "metrics=model.evaluate(x_test,y_test)\n",
    "print(\"Model accuracy = \" + str(metrics[1]))\n",
    "print(\"Model AUROC = \" + str(metrics[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb49f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpreting the performance\n",
    "* Note that while the performance is very good, it did not exceed that obtained with a convolutional model\n",
    "* It may be argued that the information in EEG is in the motifs, and not embedded in a true sequence (order-dependence)\n",
    "* In practice, the number of units and dropout parameter are extensively tuned on a \"validation\" set"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 427.847472,
   "position": {
    "height": "40px",
    "left": "1720px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
