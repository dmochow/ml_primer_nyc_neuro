{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "986d34db",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## P300 Demo\n",
    "* We will work with a dataset where subjects observed images of target and non-target objects while having their neural activity recorded with scalp EEG\n",
    "* We will create and fit a model that predicts which category of object they saw based on their observed brain activity\n",
    "* This takes the form of a binary classification problem. \n",
    "* The model that we will use is known as a \"convolutional\" network, due to it transforming the input data in a manner analogous to filtering in linear systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab955d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the data\n",
    "* The data is contained in a Matlab data file\n",
    "* We use the scipy package to conveniently bring it into the Python workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc654a6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "filename = '../data/P300.mat' # the data file\n",
    "import scipy.io as sio # the library that we use to load Matlab data into Python\n",
    "data = sio.loadmat(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f285c07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspect the data\n",
    "* The data has been partitioned into a training and test set\n",
    "* Features are shaped (example, electrode, time samples)\n",
    "* Labels are shaped (example, 2), where the 2 refers to the two classes (target vs non-target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41711b77",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training features is (1058, 64, 128)\n",
      "The shape of the training labels is (1058, 2)\n",
      "The shape of the test features is (530, 64, 128)\n",
      "The shape of the test labels is (530, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train = data['X_train']\n",
    "x_test = data['X_test']\n",
    "y_train = data['Y_train']\n",
    "y_test = data['Y_test']\n",
    "\n",
    "print(\"The shape of the training features is \" + str(x_train.shape))\n",
    "print(\"The shape of the training labels is \" + str(y_train.shape))\n",
    "print(\"The shape of the test features is \" + str(x_test.shape))\n",
    "print(\"The shape of the test labels is \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ecc90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing a sample trial\n",
    "* Looking at the data is always recommended\n",
    "* Here the data takes the form of space-time matrix, that we plot as overlaid waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c77cf",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # Python's array library\n",
    "import matplotlib.pyplot as plt # a popular library for plotting in Python\n",
    "trial_idx = 500 # let's look at trial 501\n",
    "sample_eeg = np.squeeze(x_train[trial_idx,:,:])\n",
    "plt.plot(sample_eeg.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca985f91",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspect the label information\n",
    "* It is common to label each example with a vector of probabilities\n",
    "* Below, the first element of each vector denotes P(non-target)\n",
    "* Notice above that all but one of the first 10 examples was a non-target. \n",
    "    * The 7th example was a target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f423bafb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1cb3c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating the model\n",
    "* We use the user-friendly Keras library to create a simple model for predicting target vs non-target based on the array of EEG values\n",
    "* The first layer of our model corresponds to the input data\n",
    "* The second layer performs a convolution (in effect spatial filtering) across the data in windows of 10 samples each\n",
    "* The final layer transforms the output of the convolution into a probability value\n",
    "* Our model has 881 parameters. We have 1058 examples. \n",
    "    * It's a good rule-of-thumb to have at least as many training examples as model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f61350",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 1, 119, 1)         641       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 119)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 240       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 881\n",
      "Trainable params: 881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "input_shape=(64,128,1) # this tells Keras the shape of the data that will be passed to it for training/testing\n",
    "num_classes=2\n",
    "num_filters = 1\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Conv2D(num_filters, kernel_size=(64, 10), activation=\"relu\"),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9a99b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compile the model, \n",
    "* We need to tell Keras what type of loss function we will be using, and which optimizer we would like. \n",
    "* The batch size controls how many examples are used for each computation of the gradient of the loss function\n",
    "* The number of epochs controls how many complete passes of the data we would like to make\n",
    "* We also tell Keras that we want to monitor both the model accuracy, as well as the area under the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ea6032",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128  # how many training examples in each \"batch\" used to compute gradient of loss function\n",
    "epochs = 10 # how many passes through the data we want the fitting to take\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dd10bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fitting the model\n",
    "* Keras allows you to monitor the training performance during model fitting\n",
    "* Notice that the training performance is quite good\n",
    "    * Area under the ROC curve of is ~ 0.87\n",
    "    * Now let's see how well the model generalizes to unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b453e671",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3690 - accuracy: 0.8544 - auc: 0.9202\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3558 - accuracy: 0.8629 - auc: 0.9261\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.3512 - accuracy: 0.8478 - auc: 0.9275\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3318 - accuracy: 0.8620 - auc: 0.9338\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3194 - accuracy: 0.8733 - auc: 0.9396\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.3094 - accuracy: 0.8781 - auc: 0.9432\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.3011 - accuracy: 0.8771 - auc: 0.9457\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2863 - accuracy: 0.8837 - auc: 0.9506\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2795 - accuracy: 0.8932 - auc: 0.9527\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2675 - accuracy: 0.8941 - auc: 0.9570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8fb02c6250>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aefe53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluate the model on unseen data.\n",
    "* We use the test set to assess our model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94cdd58a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8377 - auc: 0.9003\n",
      "The model accuracy is 0.8377358317375183\n",
      "The model AUROC is 0.9002670049667358\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test,y_test)\n",
    "print(\"The model accuracy is \" + str(metrics[1])) # element 0 is loss, 1 is accuracy, 2 is auroc\n",
    "print(\"The model AUROC is \" + str(metrics[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602c903",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Verify performance manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d5490",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_scores = model.predict(x_test)\n",
    "pred_labels = np.argmax(test_scores,1)\n",
    "print(test_scores[0:10,:])\n",
    "print(pred_labels[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f769b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### In the first array above, the first column is P(non-target), while the second is P(target). In the second array, the binary value indicates which class was predicted (0 for predicted non-target, 1 for predicted target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844bdefb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "true_labels = np.argmax(y_test,1)\n",
    "test_accuracy = np.mean(true_labels==pred_labels)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc9c29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's try increasing the number of convolution filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0c18c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "num_filters = 3\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Conv2D(num_filters, kernel_size=(64, 10), activation=\"relu\"),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20eb6c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Notice that we now have 3 times as many parameters. This puts us at risk of overfitting, but we proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472707b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",keras.metrics.AUC()])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1812a7a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### As expected, the training performance gets better. But we need to evaluate the model on _unseen_ data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e331248b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "metrics = model.evaluate(x_test,y_test)\n",
    "print(\"The model accuracy is \" + str(metrics[1]))\n",
    "print(\"The model AUROC is \" + str(metrics[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf8960",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Despite the number of parameters exceeding the number of training examples, the performance does get better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36a7c0",
   "metadata": {},
   "source": [
    "### Let's try to improve performance by adding regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4360c733",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "reg_l1_l2 = keras.regularizers.l1_l2(l1=0.001, l2=0.001)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Conv2D(num_filters, kernel_size=(64, 10), activation=\"relu\"),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(num_classes, activation=\"softmax\", kernel_regularizer = reg_l1_l2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18353b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### We have added both L1 and L2 regularization to the dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4948ee03",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",keras.metrics.AUC()])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "metrics = model.evaluate(x_test,y_test)\n",
    "print(\"The model accuracy is \" + str(metrics[1]))\n",
    "print(\"The model AUROC is \" + str(metrics[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f87b3f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Regularization may or may not increase the performance in this case (depends on your random seed), but now you know how to implement it in Keras ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4a9f37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Somewhat advanced: handle unequal class prevalence in the data. Note that targets are infrequent in P300 experiments (by design)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b42e43",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_labels = np.argmax(y_train,1)\n",
    "n_non_targets = np.sum(train_labels==0)\n",
    "n_targets=np.sum(train_labels==1)\n",
    "class_ratio = n_targets/n_non_targets\n",
    "print(\"The ratio of targets to non targets is \" + str(class_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce23ef0c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class_weight={0:1,1:1/class_ratio}\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",keras.metrics.AUC()])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weight)\n",
    "metrics = model.evaluate(x_test,y_test)\n",
    "print(\"The model accuracy is \" + str(metrics[1]))\n",
    "print(\"The model AUROC is \" + str(metrics[2]))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 648.38578,
   "position": {
    "height": "40px",
    "left": "1519.11px",
    "right": "20px",
    "top": "120px",
    "width": "484.774px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
