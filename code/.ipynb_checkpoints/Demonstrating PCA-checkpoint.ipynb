{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3135a2a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unsupervised Learning: PCA\n",
    "* In this exercise, we will analyze the same P300 data set but now with the most commonly used unsupervised learning method: principal components analysis (PCA).\n",
    "* The Singular Value Decomposition (SVD) provides a convenient way of performing PCA\n",
    "* We will decompose the EEG into both spatial and temporal bases\n",
    "* Once we obtain the learned components, we will use them as features into a supervised learning problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4307a743",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load in the data and extract the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63073920",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/EEG.mat' # the data file\n",
    "import scipy.io as sio # the library that we use to load Matlab data into Python\n",
    "data = sio.loadmat(filename)\n",
    "x_train = data['X_train']\n",
    "x_test = data['X_test']\n",
    "y_train = data['Y_train']\n",
    "y_test = data['Y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff109d19",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rearrange training data to two-dimensions for Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b903487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"original data:\")\n",
    "print(x_train.shape)\n",
    "x_train_ = np.swapaxes(x_train,0,1)\n",
    "x_train_ = np.swapaxes(x_train_,1,2)\n",
    "print(\"reshaped data:\")\n",
    "print(x_train_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f54c09",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Combine the time and trial dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ = np.reshape(x_train_,(x_train_.shape[0],x_train_.shape[1]*x_train_.shape[2])) \n",
    "print(\"combined data:\")\n",
    "print(x_train_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80c94f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Apply the SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,vh=np.linalg.svd(x_train_,full_matrices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b6199a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspect the singular value \"spectrum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def0231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(s, 'bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbdff86",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### The knee point occurs somewhere 7-8 components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed0d1d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reshape SVD output back to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a169c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = x_train.shape[2]\n",
    "n_examples = x_train.shape[0]\n",
    "vh_3d = np.reshape(vh,(vh.shape[0],n_samples,n_examples)) \n",
    "print(vh_3d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c544650",
   "metadata": {},
   "source": [
    "### In vh_3d, the first dimension is _component_, not electrode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da920450",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspect the mean time course of the first four components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e5d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_response = np.mean(vh_3d,axis=2) # average across trials\n",
    "fig, ax = plt.subplots(2, 2)\n",
    "ax[0,0].plot(evoked_response[0,:].T)\n",
    "ax[0,1].plot(evoked_response[1,:].T)\n",
    "ax[1,0].plot(evoked_response[2,:].T)\n",
    "ax[1,1].plot(evoked_response[3,:].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f45421",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspect the spatial topographies of the components\n",
    "* We will use the MNE package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65807a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "biosemi_montage = mne.channels.make_standard_montage('biosemi64')\n",
    "biosemi_info = mne.create_info(ch_names=biosemi_montage.ch_names, sfreq=64, ch_types='eeg')\n",
    "evoked = mne.EvokedArray(u, biosemi_info) \n",
    "evoked.set_montage(biosemi_montage)\n",
    "montage_head = evoked.get_montage()\n",
    "fake_times = evoked.times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec4c5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plot the spatial topographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77604980",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_idx=np.arange(4)\n",
    "fig,ax=plt.subplots(2,4)\n",
    "\n",
    "for i in comp_idx:\n",
    "    ax[1,i].plot(evoked_response[i,:].T)\n",
    "    ax[1,i].set_yticks([])\n",
    "    ax[1,i].set_xticks([])\n",
    "\n",
    "evoked.plot_topomap(fake_times[comp_idx],ch_type='eeg',time_unit='s',axes=ax[0,:], title='Spatial topographies', colorbar=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661ebd02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Use the spatial filters as preprocessing for supervised learning\n",
    "* The spatial filters learned by the SVD will reduce the dimensionality of the data\n",
    "* Instead of 64 electrodes, we will be working with a smaller number of components or \"virtual\" electrodes\n",
    "* Variable n_comp controls the number of components that we include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eb84cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp=7\n",
    "w = u[:,0:n_comp] # using first n_comp components\n",
    "\n",
    "x_train_new = np.swapaxes(x_train,1,2)@w  # @ denotes matrix multiplication\n",
    "x_train_new = np.swapaxes(x_train_new,1,2)\n",
    "\n",
    "x_test_new = np.swapaxes(x_test,1,2)@w\n",
    "x_test_new = np.swapaxes(x_test_new,1,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2870404a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Set up the convolutional model\n",
    "* We will use the same architecture as in the previous demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "input_shape=(n_comp,128,1) # here we are only using n_comp virtual channels\n",
    "num_classes = 2\n",
    "num_filters = 4\n",
    "kernel_dur = 10 # of samples in convolution window\n",
    "reg_l1_l2 = keras.regularizers.l1_l2(l1=0, l2=0) # no regularization due to reduced dimensionality\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Conv2D(num_filters, kernel_size=(n_comp, kernel_dur), activation=\"relu\"),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(num_classes, activation=\"softmax\", kernel_regularizer = reg_l1_l2),\n",
    "    ]\n",
    ")\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e5154",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2d413",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128  # how many training examples in each \"batch\" used to compute gradient of loss function\n",
    "epochs = 30 # how many passes through the data we want the fitting to take\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d421c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fit the model with 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8cc05e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(x_train_new, y_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c5980",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluate the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb90067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate(x_test_new,y_test)\n",
    "print(\"Model accuracy = \" + str(metrics[1]))\n",
    "print(\"Model AUROC = \" + str(metrics[2]))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 550.842472,
   "position": {
    "height": "40px",
    "left": "1620px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
